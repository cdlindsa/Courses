{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Gini Index:\n\n\nInformation Gain (Entropy):\n"
    }
   ],
   "source": [
    "# Part 1: Decision Trees with Post-pruning\n",
    "# Aspects are adapted from SENG 474 Laboratory 1, Authors unknown, Summer 2020\n",
    "import sklearn as ak\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import tree, metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import train_test_split, learning_curve, validation_curve\n",
    "from sklearn.datasets import load_files, load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree._tree import TREE_LEAF\n",
    "\n",
    "# Prunes nodes that decrease or do not change the RMSE of a tree \n",
    "def reduced_error_prune(tree, x_validate, y_validate, root):\n",
    "# Post Order Traversal of nodes\n",
    "    root_left = tree.tree_.children_left[root]\n",
    "    root_right = tree.tree_.children_right[root]\n",
    "    if (root_left!= TREE_LEAF):\n",
    "        reduced_error_prune(tree, x_validate, y_validate, root_left)\n",
    "    if (root_right!= TREE_LEAF):\n",
    "        reduced_error_prune(tree, x_validate, y_validate, root_right)\n",
    "# Test to Prune Node\n",
    "    tree = prune_index(tree, x_validate, y_validate, root)\n",
    "    return tree\n",
    "\n",
    "\n",
    "# Helper Function for Reduced Error Pruning, Sets L and R nodes to Leaves\n",
    "def prune_index(tree, x_validate, y_validate, root):\n",
    "# Store original children temporarily\n",
    "    left = tree.tree_.children_left[root]\n",
    "    right = tree.tree_.children_right[root]\n",
    "# Obtain RMSE of passed tree\n",
    "    y_pred = tree.predict(x_validate)\n",
    "    rmse = np.sqrt(metrics.mean_squared_error(y_validate, y_pred))\n",
    "# remove children\n",
    "    tree.tree_.children_left[root] = TREE_LEAF\n",
    "    tree.tree_.children_right[root] = TREE_LEAF\n",
    "# Obtain RMSE of new tree\n",
    "    y_pred_new = tree.predict(x_validate)\n",
    "    rmse_compare = np.sqrt(metrics.mean_squared_error(y_validate, y_pred_new))\n",
    "# Prune node based on lower (or equal RMSE)\n",
    "    if rmse_compare <= rmse:\n",
    "        return tree\n",
    "    else:\n",
    "        tree.tree_.children_left[root] = left\n",
    "        tree.tree_.children_right[root] = right\n",
    "        return tree\n",
    "\n",
    "# Plots validation curve data of a tree\n",
    "def validation_curve_plot(tree, data, target, train_sizes, criterion, pruned):\n",
    "    if pruned == True:\n",
    "        pruned = 'Pruned'\n",
    "    else: \n",
    "        pruned = 'Unpruned'\n",
    "    param_range = np.arange(1, 25, 2)\n",
    "    train_scores, test_scores = validation_curve(tree, data, target, param_name=\"max_depth\", param_range=param_range, scoring=\"accuracy\")\n",
    "    train_scores_mean = train_scores.mean(axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = test_scores.mean(axis=1)\n",
    "    validation_scores_std = np.std(test_scores, axis=1)\n",
    "    if criterion == 'gini':\n",
    "        criterion = 'Gini'\n",
    "    else: \n",
    "        criterion = 'Entropy'\n",
    "    plt.fill_between(param_range, validation_scores_mean - validation_scores_std, validation_scores_mean + validation_scores_std, alpha=0.1)\n",
    "    plt.fill_between(param_range, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1)\n",
    "    plt.plot(param_range, validation_scores_mean, label = 'CV score: ' +criterion + ' ' + pruned)\n",
    "    plt.plot(param_range, train_scores_mean, label = 'Training score: ' + criterion + ' ' + pruned)\n",
    "    plt.ylabel('Accuracy', fontsize = 14)\n",
    "    plt.xlabel('Max Depth', fontsize = 14)\n",
    "    plt.legend()\n",
    "\n",
    "# Plots learning curve data of a tree\n",
    "def learning_curve_plot(tree, data, target, train_sizes, criterion, pruned):\n",
    "    if pruned == True:\n",
    "        pruned = 'Pruned'\n",
    "    else: \n",
    "        pruned = 'Unpruned'\n",
    "    train_sizes, train_scores, validation_scores = learning_curve(tree, X = data, y = target, train_sizes = train_sizes, scoring = 'accuracy')\n",
    "    train_scores_mean = train_scores.mean(axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    validation_scores_mean = validation_scores.mean(axis=1)\n",
    "    validation_scores_std = np.std(validation_scores, axis=1)\n",
    "    if criterion == 'gini':\n",
    "        criterion = 'Gini'\n",
    "    else: \n",
    "        criterion = 'Entropy'\n",
    "    plt.fill_between(train_sizes, validation_scores_mean - validation_scores_std, validation_scores_mean + validation_scores_std, alpha=0.1)\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1)\n",
    "    plt.plot(train_sizes, validation_scores_mean, label = 'CV score: ' +criterion + ' ' + pruned)\n",
    "    plt.plot(train_sizes, train_scores_mean, label = 'Training score: ' + criterion + ' ' + pruned)\n",
    "    plt.ylabel('Accuracy', fontsize = 14)\n",
    "    plt.xlabel('Training set size', fontsize = 14)\n",
    "    plt.legend()\n",
    "\n",
    "# Prints the Mean Absolute Error, RMSE, Confusion Matrix, Classification Matrix, F1-Values, and Accuracy Score of the Tree's test data\n",
    "def print_info(y_test, y_pred):\n",
    "    print('\\nMean Absolute Error: ', metrics.mean_absolute_error(y_test, y_pred))\n",
    "    print('Mean Squared Error: ', metrics.mean_squared_error(y_test, y_pred))\n",
    "    print('Root Mean Squared Error: ', np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "    print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))\n",
    "    print('Classification Report:\\n', classification_report(y_test, y_pred))\n",
    "    print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Preparing Dataset Cleveland Heart Disease\n",
    "    cleveland_hd = np.loadtxt('cleaned_processed.cleveland.data', delimiter = ',')\n",
    "    size = cleveland_hd.shape[1]\n",
    "    feature_names = ['age','sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal']\n",
    "    class_names = ['no heart disease', 'heart disease']\n",
    "    data = [i[0:size-1] for i in cleveland_hd]\n",
    "    target = [i[size-1] for i in cleveland_hd]\n",
    "    x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=0)\n",
    "    amount_x = len(x_train)\n",
    "    amount_y = len(y_train)\n",
    "    train_sizes = [1, int(amount_x*0.1), int(amount_x*0.25), int(amount_x*0.5), int(amount_x*0.75), amount_x]\n",
    "\n",
    "    # Preparing Dataset Breast Cancer Data\n",
    "    # data, target = load_breast_cancer(return_X_y=True)\n",
    "    # breast_cancer = load_breast_cancer()\n",
    "    # feature_names = breast_cancer.feature_names\n",
    "    # class_names = breast_cancer.target_names\n",
    "    # x_train, x_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=0)\n",
    "    # amount_x = len(x_train)\n",
    "    # amount_y = len(y_train)\n",
    "    # train_sizes = [1, int(amount_x*0.1), int(amount_x*0.25), int(amount_x*0.5), int(amount_x*0.75), amount_x]\n",
    "\n",
    "\n",
    "    # Unmodifided Decision Tree Split based on Gini Index\n",
    "    print(\"Gini Index:\")\n",
    "    # decision_tree = tree.DecisionTreeClassifier(criterion='gini')\n",
    "    # g_clf = decision_tree.fit(x_train, y_train)\n",
    "    # y_pred = g_clf.predict(x_test)\n",
    "    # learning_curve_plot(g_clf, data, target, train_sizes, 'gini', False)\n",
    "    # validation_curve_plot(decision_tree, data, target, train_sizes, 'gini', False)\n",
    "    # print_info(y_test, y_pred)\n",
    "    # visual = tree.plot_tree(g_clf, filled=True, class_names=class_names, feature_names=feature_names)\n",
    "\n",
    "    # Post Pruning Decision Tree Split based on Gini Index\n",
    "    # g_clf = reduced_error_prune(g_clf, x_test, y_test, 0)\n",
    "    # y_pred_new = g_clf.predict(x_test)\n",
    "    # learning_curve_plot(g_clf, data, target, train_sizes, 'gini', True)\n",
    "    # print_info(y_test, y_pred_new)\n",
    "    # visual_new = tree.plot_tree(g_clf, filled=True, class_names=class_names, feature_names=feature_names)\n",
    "\n",
    "    # # Unmodifided Decision Tree Split based on Information Gain (Entropy)\n",
    "    print(\"\\n\")\n",
    "    print(\"Information Gain (Entropy):\")\n",
    "    # decision_tree = tree.DecisionTreeClassifier(criterion='entropy', max_depth=3)\n",
    "    # g_clf = decision_tree.fit(x_train, y_train)\n",
    "    # y_pred = g_clf.predict(x_test)\n",
    "    # learning_curve_plot(g_clf, data, target, train_sizes, 'entropy', False)\n",
    "    # validation_curve_plot(decision_tree, data, target, train_sizes, 'entropy', False)\n",
    "    # print_info(y_test, y_pred)\n",
    "    # visual = tree.plot_tree(g_clf, filled=True, class_names=class_names, feature_names=feature_names)\n",
    "\n",
    "    # Post Pruning Decision Tree Split based on Information Gain (Entropy)\n",
    "    # g_clf = reduced_error_prune(g_clf, x_test, y_test, 0)\n",
    "    # y_pred_new = g_clf.predict(x_test)\n",
    "    # learning_curve_plot(g_clf, data, target, train_sizes, 'entropy', True)\n",
    "    # print_info(y_test, y_pred_new)\n",
    "    # visual_new = tree.plot_tree(g_clf, filled=True, class_names=class_names, feature_names=feature_names)\n",
    "\n",
    "    # title = 'Validation Curve For Unconstrained Decision Tree Split With Gini Index'\n",
    "    # title = 'Validation Curve For Unconstrained Decision Tree Split With Entropy'\n",
    "    # plt.title(title, fontsize = 18, y = 1.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}